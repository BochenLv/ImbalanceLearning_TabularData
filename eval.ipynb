{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, roc_auc_score, f1_score, accuracy_score, classification_report\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this notebook, we use the LightGBM as baseline model for future comparison.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1484 entries, 0 to 1483\nData columns (total 9 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Label   1484 non-null   int64  \n 1   Mcg     1484 non-null   float64\n 2    Gvh    1484 non-null   float64\n 3    Alm    1484 non-null   float64\n 4    Mit    1484 non-null   float64\n 5    Erl    1484 non-null   float64\n 6    Pox    1484 non-null   float64\n 7    Vac    1484 non-null   float64\n 8    Nuc    1484 non-null   float64\ndtypes: float64(8), int64(1)\nmemory usage: 104.5 KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./datasets/yeast4.csv')\n",
    "data['Label'] = data['Label'].apply(lambda x: x.replace('positive', '1').replace('negative', '0')).astype('int')\n",
    "# data['Label'] = data['Label'].astype('category')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.Label\n",
    "X = data.drop('Label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Mcg   Gvh   Alm   Mit   Erl   Pox   Vac   Nuc\n",
       "0     0.58  0.61  0.47  0.13   0.5   0.0  0.48  0.22\n",
       "1     0.43  0.67  0.48  0.27   0.5   0.0  0.53  0.22\n",
       "2     0.64  0.62  0.49  0.15   0.5   0.0  0.53  0.22\n",
       "3     0.42  0.44  0.48  0.54   0.5   0.0  0.48  0.22\n",
       "4     0.50  0.54  0.48  0.65   0.5   0.0  0.53  0.22\n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...\n",
       "1479  0.36  0.48  0.61  0.26   0.5   0.0  0.50  0.16\n",
       "1480  0.30  0.37  0.40  0.45   0.5   0.0  0.48  0.41\n",
       "1481  0.38  0.40  0.39  0.19   0.5   0.0  0.46  0.62\n",
       "1482  0.58  0.56  0.38  0.39   0.5   0.0  0.54  0.57\n",
       "1483  0.67  0.57  0.36  0.19   0.5   0.0  0.56  0.22\n",
       "\n",
       "[1484 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mcg</th>\n      <th>Gvh</th>\n      <th>Alm</th>\n      <th>Mit</th>\n      <th>Erl</th>\n      <th>Pox</th>\n      <th>Vac</th>\n      <th>Nuc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.58</td>\n      <td>0.61</td>\n      <td>0.47</td>\n      <td>0.13</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.48</td>\n      <td>0.22</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.43</td>\n      <td>0.67</td>\n      <td>0.48</td>\n      <td>0.27</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.53</td>\n      <td>0.22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.64</td>\n      <td>0.62</td>\n      <td>0.49</td>\n      <td>0.15</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.53</td>\n      <td>0.22</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.42</td>\n      <td>0.44</td>\n      <td>0.48</td>\n      <td>0.54</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.48</td>\n      <td>0.22</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.50</td>\n      <td>0.54</td>\n      <td>0.48</td>\n      <td>0.65</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.53</td>\n      <td>0.22</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1479</th>\n      <td>0.36</td>\n      <td>0.48</td>\n      <td>0.61</td>\n      <td>0.26</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.16</td>\n    </tr>\n    <tr>\n      <th>1480</th>\n      <td>0.30</td>\n      <td>0.37</td>\n      <td>0.40</td>\n      <td>0.45</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.48</td>\n      <td>0.41</td>\n    </tr>\n    <tr>\n      <th>1481</th>\n      <td>0.38</td>\n      <td>0.40</td>\n      <td>0.39</td>\n      <td>0.19</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.46</td>\n      <td>0.62</td>\n    </tr>\n    <tr>\n      <th>1482</th>\n      <td>0.58</td>\n      <td>0.56</td>\n      <td>0.38</td>\n      <td>0.39</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.54</td>\n      <td>0.57</td>\n    </tr>\n    <tr>\n      <th>1483</th>\n      <td>0.67</td>\n      <td>0.57</td>\n      <td>0.36</td>\n      <td>0.19</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.56</td>\n      <td>0.22</td>\n    </tr>\n  </tbody>\n</table>\n<p>1484 rows Ã— 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1479    0\n",
       "1480    0\n",
       "1481    0\n",
       "1482    0\n",
       "1483    1\n",
       "Name: Label, Length: 1484, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "train_data = lightgbm.Dataset(X_train, label=y_train)\n",
    "val_data = lightgbm.Dataset(X_val, label=y_val)\n",
    "test_data = lightgbm.Dataset(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_test, y_test, model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Accuracy of the model: {}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "    print('Classification report: \\n{}\\n'.format(classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_param = {\n",
    "        'n_estimators': 3000,\n",
    "        'max_depth': 100,\n",
    "        'objective': 'binary',\n",
    "        'num_leaves': 400,\n",
    "        'feature_fraction': 0.64,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'learning_rate':0.02,\n",
    "        'verbose': -1,\n",
    "        'force_col_wise': True,\n",
    "        'is_unbalance': True,\n",
    "        'boosting_type': 'gbdt',\n",
    "}\n",
    "\n",
    "lgb = lightgbm.LGBMClassifier(**lgbm_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Accuracy of the model: 0.957983193277311\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       114\n",
      "           1       0.50      0.40      0.44         5\n",
      "\n",
      "    accuracy                           0.96       119\n",
      "   macro avg       0.74      0.69      0.71       119\n",
      "weighted avg       0.95      0.96      0.96       119\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgb.fit(X_train, y_train)\n",
    "y_v_pred = lgb.predict(X_val)\n",
    "evaluate_model(y_val, y_v_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the model: 0.9562289562289562\n\nClassification report: \n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98       287\n           1       0.20      0.10      0.13        10\n\n    accuracy                           0.96       297\n   macro avg       0.58      0.54      0.56       297\nweighted avg       0.94      0.96      0.95       297\n\n\n"
     ]
    }
   ],
   "source": [
    "y_t_pred = lgb.predict(X_test)\n",
    "evaluate_model(y_test, y_t_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "y_ntest = y_test.reset_index(drop=True)\n",
    "z = []\n",
    "idx_dic = y_ntest.to_dict()\n",
    "idx_dic\n",
    "for k, p in idx_dic.items():\n",
    "    if p == 1:\n",
    "        z.append(k)\n",
    "X_ntest = X_test.reset_index(drop=True)\n",
    "X_mtest = X_ntest.iloc[z]\n",
    "y_mtest = y_ntest.iloc[z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the model: 0.1\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.10      0.18        10\n",
      "\n",
      "    accuracy                           0.10        10\n",
      "   macro avg       0.50      0.05      0.09        10\n",
      "weighted avg       1.00      0.10      0.18        10\n",
      "\n",
      "\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_m_pred = lgb.predict(X_mtest)\n",
    "evaluate_model(y_mtest, y_m_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "y_m_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1599 entries, 0 to 1598\nData columns (total 12 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   Label                1599 non-null   int64  \n 1   FixedAcidity         1599 non-null   float64\n 2    VolatileAcidity     1599 non-null   float64\n 3    CitricAcid          1599 non-null   float64\n 4    ResidualSugar       1599 non-null   float64\n 5    Chlorides           1599 non-null   float64\n 6    FreeSulfurDioxide   1599 non-null   float64\n 7    TotalSulfurDioxide  1599 non-null   float64\n 8    Density             1599 non-null   float64\n 9    PH                  1599 non-null   float64\n 10   Sulphates           1599 non-null   float64\n 11   Alcohol             1599 non-null   float64\ndtypes: float64(11), int64(1)\nmemory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "# dataset2\n",
    "data1 = pd.read_csv('./datasets/winequality.csv')\n",
    "data1['Label'] = data1['Label'].apply(lambda x: x.replace('positive', '1').replace('negative', '0')).astype('int')\n",
    "# data['Label'] = data['Label'].astype('category')\n",
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      FixedAcidity   VolatileAcidity   CitricAcid   ResidualSugar   Chlorides  \\\n",
       "0              7.4             0.700         0.00             1.9       0.076   \n",
       "1              7.8             0.880         0.00             2.6       0.098   \n",
       "2              7.8             0.760         0.04             2.3       0.092   \n",
       "3             11.2             0.280         0.56             1.9       0.075   \n",
       "4              7.4             0.700         0.00             1.9       0.076   \n",
       "...            ...               ...          ...             ...         ...   \n",
       "1594           6.2             0.600         0.08             2.0       0.090   \n",
       "1595           5.9             0.550         0.10             2.2       0.062   \n",
       "1596           6.3             0.510         0.13             2.3       0.076   \n",
       "1597           5.9             0.645         0.12             2.0       0.075   \n",
       "1598           6.0             0.310         0.47             3.6       0.067   \n",
       "\n",
       "       FreeSulfurDioxide   TotalSulfurDioxide   Density    PH   Sulphates  \\\n",
       "0                   11.0                 34.0   0.99780  3.51        0.56   \n",
       "1                   25.0                 67.0   0.99680  3.20        0.68   \n",
       "2                   15.0                 54.0   0.99700  3.26        0.65   \n",
       "3                   17.0                 60.0   0.99800  3.16        0.58   \n",
       "4                   11.0                 34.0   0.99780  3.51        0.56   \n",
       "...                  ...                  ...       ...   ...         ...   \n",
       "1594                32.0                 44.0   0.99490  3.45        0.58   \n",
       "1595                39.0                 51.0   0.99512  3.52        0.76   \n",
       "1596                29.0                 40.0   0.99574  3.42        0.75   \n",
       "1597                32.0                 44.0   0.99547  3.57        0.71   \n",
       "1598                18.0                 42.0   0.99549  3.39        0.66   \n",
       "\n",
       "       Alcohol  \n",
       "0          9.4  \n",
       "1          9.8  \n",
       "2          9.8  \n",
       "3          9.8  \n",
       "4          9.4  \n",
       "...        ...  \n",
       "1594      10.5  \n",
       "1595      11.2  \n",
       "1596      11.0  \n",
       "1597      10.2  \n",
       "1598      11.0  \n",
       "\n",
       "[1599 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FixedAcidity</th>\n      <th>VolatileAcidity</th>\n      <th>CitricAcid</th>\n      <th>ResidualSugar</th>\n      <th>Chlorides</th>\n      <th>FreeSulfurDioxide</th>\n      <th>TotalSulfurDioxide</th>\n      <th>Density</th>\n      <th>PH</th>\n      <th>Sulphates</th>\n      <th>Alcohol</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.4</td>\n      <td>0.700</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.8</td>\n      <td>0.880</td>\n      <td>0.00</td>\n      <td>2.6</td>\n      <td>0.098</td>\n      <td>25.0</td>\n      <td>67.0</td>\n      <td>0.99680</td>\n      <td>3.20</td>\n      <td>0.68</td>\n      <td>9.8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.8</td>\n      <td>0.760</td>\n      <td>0.04</td>\n      <td>2.3</td>\n      <td>0.092</td>\n      <td>15.0</td>\n      <td>54.0</td>\n      <td>0.99700</td>\n      <td>3.26</td>\n      <td>0.65</td>\n      <td>9.8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.2</td>\n      <td>0.280</td>\n      <td>0.56</td>\n      <td>1.9</td>\n      <td>0.075</td>\n      <td>17.0</td>\n      <td>60.0</td>\n      <td>0.99800</td>\n      <td>3.16</td>\n      <td>0.58</td>\n      <td>9.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.4</td>\n      <td>0.700</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1594</th>\n      <td>6.2</td>\n      <td>0.600</td>\n      <td>0.08</td>\n      <td>2.0</td>\n      <td>0.090</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99490</td>\n      <td>3.45</td>\n      <td>0.58</td>\n      <td>10.5</td>\n    </tr>\n    <tr>\n      <th>1595</th>\n      <td>5.9</td>\n      <td>0.550</td>\n      <td>0.10</td>\n      <td>2.2</td>\n      <td>0.062</td>\n      <td>39.0</td>\n      <td>51.0</td>\n      <td>0.99512</td>\n      <td>3.52</td>\n      <td>0.76</td>\n      <td>11.2</td>\n    </tr>\n    <tr>\n      <th>1596</th>\n      <td>6.3</td>\n      <td>0.510</td>\n      <td>0.13</td>\n      <td>2.3</td>\n      <td>0.076</td>\n      <td>29.0</td>\n      <td>40.0</td>\n      <td>0.99574</td>\n      <td>3.42</td>\n      <td>0.75</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>1597</th>\n      <td>5.9</td>\n      <td>0.645</td>\n      <td>0.12</td>\n      <td>2.0</td>\n      <td>0.075</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99547</td>\n      <td>3.57</td>\n      <td>0.71</td>\n      <td>10.2</td>\n    </tr>\n    <tr>\n      <th>1598</th>\n      <td>6.0</td>\n      <td>0.310</td>\n      <td>0.47</td>\n      <td>3.6</td>\n      <td>0.067</td>\n      <td>18.0</td>\n      <td>42.0</td>\n      <td>0.99549</td>\n      <td>3.39</td>\n      <td>0.66</td>\n      <td>11.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1599 rows Ã— 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "y1 = data1.Label\n",
    "X1 = data1.drop('Label', axis=1)\n",
    "X1"
   ]
  },
  {
   "source": [
    "y1"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1594    0\n",
       "1595    0\n",
       "1596    0\n",
       "1597    0\n",
       "1598    0\n",
       "Name: Label, Length: 1599, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, X1_test, y1, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "X1_train, X1_val, y1_train, y1_val = train_test_split(X1, y1, test_size=0.1, random_state=1)\n",
    "train_data1 = lightgbm.Dataset(X1_train, label=y1_train)\n",
    "val_data1 = lightgbm.Dataset(X1_val, label=y1_val)\n",
    "test_data1 = lightgbm.Dataset(X1_test, label=y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Accuracy of the model: 0.953125\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       122\n",
      "           1       0.50      0.17      0.25         6\n",
      "\n",
      "    accuracy                           0.95       128\n",
      "   macro avg       0.73      0.58      0.61       128\n",
      "weighted avg       0.94      0.95      0.94       128\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm_param1 = {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 1000,\n",
    "        'objective': 'binary',\n",
    "        'num_leaves': 1000,\n",
    "        'feature_fraction': 0.64,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'learning_rate':0.05,\n",
    "        'verbose': -1,\n",
    "        'force_col_wise': True,\n",
    "        'is_unbalance': True,\n",
    "        'boosting_type': 'gbdt',\n",
    "}\n",
    "\n",
    "lgb1 = lightgbm.LGBMClassifier(**lgbm_param1)\n",
    "lgb1.fit(X1_train, y1_train)\n",
    "y1_v_pred = lgb1.predict(X1_val)\n",
    "evaluate_model(y1_val, y1_v_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_ntest = y1_test.reset_index(drop=True)\n",
    "z = []\n",
    "idx_dic1 = y1_ntest.to_dict()\n",
    "for k, p in idx_dic1.items():\n",
    "    if p == 1:\n",
    "        z.append(k)\n",
    "X1_ntest = X1_test.reset_index(drop=True)\n",
    "X1_mtest = X1_ntest.iloc[z]\n",
    "y1_mtest = y1_ntest.iloc[z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the model: 0.0\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           1       0.00      0.00      0.00      10.0\n",
      "\n",
      "    accuracy                           0.00      10.0\n",
      "   macro avg       0.00      0.00      0.00      10.0\n",
      "weighted avg       0.00      0.00      0.00      10.0\n",
      "\n",
      "\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y1_m_pred = lgb1.predict(X1_mtest)\n",
    "evaluate_model(y1_mtest, y1_m_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "y1_m_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0    1032\n1    1032\nName: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We now try to use the Random OverSampling technique to resolve the imbalance problem.\n",
    "\"\"\"\n",
    "train_set = pd.concat([X_train, y_train], axis=1)\n",
    "count_0, count_1 = train_set.Label.value_counts()\n",
    "data_0 = train_set[train_set['Label'] == 0]\n",
    "data_1 = train_set[train_set['Label'] == 1]\n",
    "\n",
    "data_1_over = data_1.sample(count_0, replace=True)\n",
    "data_over = pd.concat([data_0, data_1_over], axis=0)\n",
    "\n",
    "print(data_over.Label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_over = data_over.Label\n",
    "X_over = data_over.drop('Label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the model: 0.9831932773109243\n\nClassification report: \n              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99       114\n           1       1.00      0.60      0.75         5\n\n    accuracy                           0.98       119\n   macro avg       0.99      0.80      0.87       119\nweighted avg       0.98      0.98      0.98       119\n\n\n"
     ]
    }
   ],
   "source": [
    "lgbm_param2 = {\n",
    "        'n_estimators': 1000,\n",
    "        'max_depth': 1000,\n",
    "        'objective': 'binary',\n",
    "        'num_leaves': 100,\n",
    "        'learning_rate':0.01,\n",
    "        'verbose': -1,\n",
    "        'force_col_wise': True,\n",
    "        'is_unbalance': True,\n",
    "        'boosting_type': 'gbdt',\n",
    "}\n",
    "\n",
    "lgb2 = lightgbm.LGBMClassifier(**lgbm_param2)\n",
    "lgb2.fit(X_over, y_over)\n",
    "evaluate_model(X_val, y_val, lgb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the model: 0.9629629629629629\n\nClassification report: \n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98       287\n           1       0.40      0.20      0.27        10\n\n    accuracy                           0.96       297\n   macro avg       0.69      0.59      0.62       297\nweighted avg       0.95      0.96      0.96       297\n\n\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(X_test, y_test, lgb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the model: 0.2\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.20      0.33        10\n",
      "\n",
      "    accuracy                           0.20        10\n",
      "   macro avg       0.50      0.10      0.17        10\n",
      "weighted avg       1.00      0.20      0.33        10\n",
      "\n",
      "\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(X_mtest, y_mtest, lgb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 1, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "lgb2.predict(X_mtest) # although useful to some extent, the result is bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0    1114\n1    1114\nName: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from data_manipulation.random_sampling import ros\n",
    "data1_over = ros(X1_train, y1_train)\n",
    "y1_over = data1_over.Label\n",
    "X1_over = data1_over.drop('Label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the model: 0.9375\n\nClassification report: \n              precision    recall  f1-score   support\n\n           0       0.96      0.98      0.97       122\n           1       0.25      0.17      0.20         6\n\n    accuracy                           0.94       128\n   macro avg       0.60      0.57      0.58       128\nweighted avg       0.93      0.94      0.93       128\n\n\n"
     ]
    }
   ],
   "source": [
    "lgbm_param3 = {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 1000,\n",
    "        'objective': 'binary',\n",
    "        'num_leaves': 500,\n",
    "        'learning_rate':0.02,\n",
    "        'verbose': -1,\n",
    "        'force_col_wise': True,\n",
    "        'is_unbalance': True,\n",
    "        'boosting_type': 'gbdt',\n",
    "}\n",
    "\n",
    "lgb3 = lightgbm.LGBMClassifier(**lgbm_param3)\n",
    "lgb3.fit(X1_over, y1_over)\n",
    "evaluate_model(X1_val, y1_val, lgb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the model: 0.0\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           1       0.00      0.00      0.00      10.0\n",
      "\n",
      "    accuracy                           0.00      10.0\n",
      "   macro avg       0.00      0.00      0.00      10.0\n",
      "weighted avg       0.00      0.00      0.00      10.0\n",
      "\n",
      "\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(X1_mtest, y1_mtest, lgb3) # does not work, even hurt the performance on the whole dataset"
   ]
  }
 ]
}